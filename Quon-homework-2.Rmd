---
title: "Homework 2"
author: "Ryan Quon"
output:
    html_document:
      toc: true
      toc_float: true
      code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)
```

## Linear Regression

For this lab, we will be working with a data set from the UCI (University of California, Irvine) Machine Learning repository ([see website here](http://archive.ics.uci.edu/ml/datasets/Abalone)). The full data set consists of $4,177$ observations of abalone in Tasmania. (Fun fact: [Tasmania](https://en.wikipedia.org/wiki/Tasmania "Tasmania") supplies about $25\%$ of the yearly world abalone harvest.)

![*Fig 1. Inside of an abalone shell.*](https://cdn.shopify.com/s/files/1/1198/8002/products/1d89434927bffb6fd1786c19c2d921fb_2000x_652a2391-5a0a-4f10-966c-f759dc08635c_1024x1024.jpg?v=1582320404){width="152"}

The age of an abalone is typically determined by cutting the shell open and counting the number of rings with a microscope. The purpose of this data set is to determine whether abalone age (**number of rings + 1.5**) can be accurately predicted using other, easier-to-obtain information about the abalone.

The full abalone data set is located in the `\data` subdirectory. Read it into *R* using `read_csv()`. Take a moment to read through the codebook (`abalone_codebook.txt`) and familiarize yourself with the variable definitions.

Make sure you load the `tidyverse` and `tidymodels`!

```{r}
library(tidyverse)
library(tidymodels)
library(yardstick)
data <- read_csv("C:/Users/ryanc/OneDrive/Desktop/PSTAT131/homework-2/homework-2/data/abalone.csv")
```

### Question 1

Your goal is to predict abalone age, which is calculated as the number of rings plus 1.5. Notice there currently is no `age` variable in the data set. Add `age` to the data set.

Assess and describe the distribution of `age`.

The distribution of age is roughly normally distributed, single peaked but does have a slight right skew. There also appears to be a few outliers in the age variable.
```{r}
data <- data %>%
  mutate(age = rings + 1.5) %>%
  select(-rings)

ggplot(data, aes(x = age)) + geom_bar(fill = "dark green")

```


### Question 2

Split the abalone data into a training set and a testing set. Use stratified sampling. You should decide on appropriate percentages for splitting the data.

*Remember that you'll need to set a seed at the beginning of the document to reproduce your results.*

```{r}
set.seed(265)

data_split <- initial_split(data, prop = 0.80,
                                strata = age)
data_train <- training(data_split)
data_test <- testing(data_split)
```


### Question 3

Using the **training** data, create a recipe predicting the outcome variable, `age`, with all other predictor variables. Note that you should not include `rings` to predict `age`. Explain why you shouldn't use `rings` to predict `age`.

Answer: We should not use rings to predict age since they are correlated.

Steps for your recipe:

1.  dummy code any categorical predictors

2.  create interactions between

    -   `type` and `shucked_weight`,
    -   `longest_shell` and `diameter`,
    -   `shucked_weight` and `shell_weight`

3.  center all predictors, and

4.  scale all predictors.

You'll need to investigate the `tidymodels` documentation to find the appropriate step functions to use.

```{r}
lm_recipe <- recipe(age ~ ., data = data_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_interact(terms = ~ starts_with("type"):shucked_weight + longest_shell:diameter + shucked_weight:shell_weight) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
View(data_train)

```

### Question 4

Create and store a linear regression object using the `"lm"` engine.

```{r}
lm_model <- linear_reg() %>% 
  set_engine("lm")
```


### Question 5

Now:

1.  set up an empty workflow,
2.  add the model you created in Question 4, and
3.  add the recipe that you created in Question 3.

```{r}
lm_flow <- workflow() %>%
  add_model(lm_model) %>%
  add_recipe(lm_recipe)
```


### Question 6

Use your `fit()` object to predict the age of a hypothetical female abalone with longest_shell = 0.50, diameter = 0.10, height = 0.30, whole_weight = 4, shucked_weight = 1, viscera_weight = 2, shell_weight = 1.

```{r}
lm_fit <- fit(lm_flow,data_train)

lm_fit %>% 
  # This returns the parsnip object:
  extract_fit_parsnip() %>% 
  # Now tidy the linear model object:
  tidy()

values_table <- tibble(type = "F", 
                       longest_shell = 0.50, 
                       diameter = 0.10, 
                       height = 0.30, 
                       whole_weight = 4, 
                       shucked_weight = 1, 
                       viscera_weight = 2, 
                       shell_weight = 1,
                       age = NA)

# Prediction using values from the tibble
q6 <- predict(lm_fit, new_data = values_table)
q6 %>% head()

```

### Question 7

Now you want to assess your model's performance. To do this, use the `yardstick` package:

1.  Create a metric set that includes *R^2^*, RMSE (root mean squared error), and MAE (mean absolute error).
2.  Use `predict()` and `bind_cols()` to create a tibble of your model's predicted values from the **training data** along with the actual observed ages (these are needed to assess your model's performance).
3.  Finally, apply your metric set to the tibble, report the results, and interpret the *R^2^* value.

```{r}

# actual vs predicted using the training data
abalone_predict <- predict(lm_fit, new_data = data_train %>% select(-age))
abalone_predict <- bind_cols(abalone_predict, data_train %>% select(age))

abalone_predict <- abalone_predict %>%
  mutate(Difference = .pred-age)

abalone_predict


#metric set 
abalone_metric_set <- metric_set(rmse, rsq, mae)
abalone_metric_set <- abalone_metric_set(abalone_predict, truth = age, 
                estimate = .pred)
tibble(abalone_metric_set)



```


#### 7c)
$$R^2 = .562$$ means that 56.2% of the variance in the data can be explained by the model. This number is low as it is not close to 100%. There is a significant amount of variance unexplained so the model needs improvement.

Through the boxplot of the prediction - actual age differences, we can see the data's mean is near 0 but there are numerous outliers.
```{r}
ggplot(abalone_predict, aes(x=Difference)) + geom_boxplot()
```



